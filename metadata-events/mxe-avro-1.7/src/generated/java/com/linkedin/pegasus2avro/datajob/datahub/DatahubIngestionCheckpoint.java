/**
 * Autogenerated by Avro
 * 
 * DO NOT EDIT DIRECTLY
 */
package com.linkedin.pegasus2avro.datajob.datahub;  
@SuppressWarnings("all")
/** Checkpoint of a datahub ingestion run for a given job. */
@org.apache.avro.specific.AvroGenerated
public class DatahubIngestionCheckpoint extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse("{\"type\":\"record\",\"name\":\"DatahubIngestionCheckpoint\",\"namespace\":\"com.linkedin.pegasus2avro.datajob.datahub\",\"doc\":\"Checkpoint of a datahub ingestion run for a given job.\",\"fields\":[{\"name\":\"timestampMillis\",\"type\":\"long\",\"doc\":\"The event timestamp field as epoch at UTC in milli seconds.\"},{\"name\":\"eventGranularity\",\"type\":[\"null\",{\"type\":\"record\",\"name\":\"TimeWindowSize\",\"namespace\":\"com.linkedin.pegasus2avro.timeseries\",\"doc\":\"Defines the size of a time window.\",\"fields\":[{\"name\":\"unit\",\"type\":{\"type\":\"enum\",\"name\":\"CalendarInterval\",\"symbols\":[\"SECOND\",\"MINUTE\",\"HOUR\",\"DAY\",\"WEEK\",\"MONTH\",\"QUARTER\",\"YEAR\"]},\"doc\":\"Interval unit such as minute/hour/day etc.\"},{\"name\":\"multiple\",\"type\":\"int\",\"doc\":\"How many units. Defaults to 1.\",\"default\":1}]}],\"doc\":\"Granularity of the event if applicable\",\"default\":null},{\"name\":\"partitionSpec\",\"type\":[{\"type\":\"record\",\"name\":\"PartitionSpec\",\"namespace\":\"com.linkedin.pegasus2avro.timeseries\",\"doc\":\"Defines how the data is partitioned\",\"fields\":[{\"name\":\"type\",\"type\":{\"type\":\"enum\",\"name\":\"PartitionType\",\"symbols\":[\"FULL_TABLE\",\"QUERY\",\"PARTITION\"]},\"default\":\"PARTITION\"},{\"name\":\"partition\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"},\"doc\":\"String representation of the partition\",\"TimeseriesField\":{}},{\"name\":\"timePartition\",\"type\":[\"null\",{\"type\":\"record\",\"name\":\"TimeWindow\",\"fields\":[{\"name\":\"startTimeMillis\",\"type\":\"long\",\"doc\":\"Start time as epoch at UTC.\"},{\"name\":\"length\",\"type\":\"TimeWindowSize\",\"doc\":\"The length of the window.\"}]}],\"doc\":\"Time window of the partition if applicable\",\"default\":null}]},\"null\"],\"doc\":\"The optional partition specification.\",\"default\":{\"partition\":\"FULL_TABLE_SNAPSHOT\",\"type\":\"FULL_TABLE\",\"timePartition\":null}},{\"name\":\"messageId\",\"type\":[\"null\",{\"type\":\"string\",\"avro.java.string\":\"String\"}],\"doc\":\"The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.\",\"default\":null},{\"name\":\"pipelineName\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"},\"doc\":\"The name of the pipeline that ran ingestion, a stable unique user provided identifier.\\n e.g. my_snowflake1-to-datahub.\",\"TimeseriesField\":{}},{\"name\":\"platformInstanceId\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"},\"doc\":\"The id of the instance against which the ingestion pipeline ran.\\ne.g.: Bigquery project ids, MySQL hostnames etc.\",\"TimeseriesField\":{}},{\"name\":\"config\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"},\"doc\":\"Json-encoded string representation of the non-secret members of the config .\"},{\"name\":\"state\",\"type\":{\"type\":\"record\",\"name\":\"IngestionCheckpointState\",\"doc\":\"The checkpoint state object of a datahub ingestion run for a given job.\",\"fields\":[{\"name\":\"formatVersion\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"},\"doc\":\"The version of the state format.\"},{\"name\":\"serde\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"},\"doc\":\"The serialization/deserialization protocol.\"},{\"name\":\"payload\",\"type\":[\"null\",\"bytes\"],\"doc\":\"Opaque blob of the state representation.\",\"default\":null}]},\"doc\":\"Opaque blob of the state representation.\"},{\"name\":\"runId\",\"type\":{\"type\":\"string\",\"avro.java.string\":\"String\"},\"doc\":\"The run identifier of this job.\",\"TimeseriesField\":{}}],\"Aspect\":{\"name\":\"datahubIngestionCheckpoint\",\"type\":\"timeseries\"}}");
  public static org.apache.avro.Schema getClassSchema() { return SCHEMA$; }
  /** The event timestamp field as epoch at UTC in milli seconds. */
  @Deprecated public long timestampMillis;
  /** Granularity of the event if applicable */
  @Deprecated public com.linkedin.pegasus2avro.timeseries.TimeWindowSize eventGranularity;
  /** The optional partition specification. */
  @Deprecated public com.linkedin.pegasus2avro.timeseries.PartitionSpec partitionSpec;
  /** The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value. */
  @Deprecated public java.lang.String messageId;
  /** The name of the pipeline that ran ingestion, a stable unique user provided identifier.
 e.g. my_snowflake1-to-datahub. */
  @Deprecated public java.lang.String pipelineName;
  /** The id of the instance against which the ingestion pipeline ran.
e.g.: Bigquery project ids, MySQL hostnames etc. */
  @Deprecated public java.lang.String platformInstanceId;
  /** Json-encoded string representation of the non-secret members of the config . */
  @Deprecated public java.lang.String config;
  /** Opaque blob of the state representation. */
  @Deprecated public com.linkedin.pegasus2avro.datajob.datahub.IngestionCheckpointState state;
  /** The run identifier of this job. */
  @Deprecated public java.lang.String runId;

  /**
   * Default constructor.  Note that this does not initialize fields
   * to their default values from the schema.  If that is desired then
   * one should use <code>newBuilder()</code>. 
   */
  public DatahubIngestionCheckpoint() {}

  /**
   * All-args constructor.
   */
  public DatahubIngestionCheckpoint(java.lang.Long timestampMillis, com.linkedin.pegasus2avro.timeseries.TimeWindowSize eventGranularity, com.linkedin.pegasus2avro.timeseries.PartitionSpec partitionSpec, java.lang.String messageId, java.lang.String pipelineName, java.lang.String platformInstanceId, java.lang.String config, com.linkedin.pegasus2avro.datajob.datahub.IngestionCheckpointState state, java.lang.String runId) {
    this.timestampMillis = timestampMillis;
    this.eventGranularity = eventGranularity;
    this.partitionSpec = partitionSpec;
    this.messageId = messageId;
    this.pipelineName = pipelineName;
    this.platformInstanceId = platformInstanceId;
    this.config = config;
    this.state = state;
    this.runId = runId;
  }

  public org.apache.avro.Schema getSchema() { return SCHEMA$; }
  // Used by DatumWriter.  Applications should not call. 
  public java.lang.Object get(int field$) {
    switch (field$) {
    case 0: return timestampMillis;
    case 1: return eventGranularity;
    case 2: return partitionSpec;
    case 3: return messageId;
    case 4: return pipelineName;
    case 5: return platformInstanceId;
    case 6: return config;
    case 7: return state;
    case 8: return runId;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }
  // Used by DatumReader.  Applications should not call. 
  @SuppressWarnings(value="unchecked")
  public void put(int field$, java.lang.Object value$) {
    switch (field$) {
    case 0: timestampMillis = (java.lang.Long)value$; break;
    case 1: eventGranularity = (com.linkedin.pegasus2avro.timeseries.TimeWindowSize)value$; break;
    case 2: partitionSpec = (com.linkedin.pegasus2avro.timeseries.PartitionSpec)value$; break;
    case 3: messageId = (java.lang.String)value$; break;
    case 4: pipelineName = (java.lang.String)value$; break;
    case 5: platformInstanceId = (java.lang.String)value$; break;
    case 6: config = (java.lang.String)value$; break;
    case 7: state = (com.linkedin.pegasus2avro.datajob.datahub.IngestionCheckpointState)value$; break;
    case 8: runId = (java.lang.String)value$; break;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }

  /**
   * Gets the value of the 'timestampMillis' field.
   * The event timestamp field as epoch at UTC in milli seconds.   */
  public java.lang.Long getTimestampMillis() {
    return timestampMillis;
  }

  /**
   * Sets the value of the 'timestampMillis' field.
   * The event timestamp field as epoch at UTC in milli seconds.   * @param value the value to set.
   */
  public void setTimestampMillis(java.lang.Long value) {
    this.timestampMillis = value;
  }

  /**
   * Gets the value of the 'eventGranularity' field.
   * Granularity of the event if applicable   */
  public com.linkedin.pegasus2avro.timeseries.TimeWindowSize getEventGranularity() {
    return eventGranularity;
  }

  /**
   * Sets the value of the 'eventGranularity' field.
   * Granularity of the event if applicable   * @param value the value to set.
   */
  public void setEventGranularity(com.linkedin.pegasus2avro.timeseries.TimeWindowSize value) {
    this.eventGranularity = value;
  }

  /**
   * Gets the value of the 'partitionSpec' field.
   * The optional partition specification.   */
  public com.linkedin.pegasus2avro.timeseries.PartitionSpec getPartitionSpec() {
    return partitionSpec;
  }

  /**
   * Sets the value of the 'partitionSpec' field.
   * The optional partition specification.   * @param value the value to set.
   */
  public void setPartitionSpec(com.linkedin.pegasus2avro.timeseries.PartitionSpec value) {
    this.partitionSpec = value;
  }

  /**
   * Gets the value of the 'messageId' field.
   * The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.   */
  public java.lang.String getMessageId() {
    return messageId;
  }

  /**
   * Sets the value of the 'messageId' field.
   * The optional messageId, if provided serves as a custom user-defined unique identifier for an aspect value.   * @param value the value to set.
   */
  public void setMessageId(java.lang.String value) {
    this.messageId = value;
  }

  /**
   * Gets the value of the 'pipelineName' field.
   * The name of the pipeline that ran ingestion, a stable unique user provided identifier.
 e.g. my_snowflake1-to-datahub.   */
  public java.lang.String getPipelineName() {
    return pipelineName;
  }

  /**
   * Sets the value of the 'pipelineName' field.
   * The name of the pipeline that ran ingestion, a stable unique user provided identifier.
 e.g. my_snowflake1-to-datahub.   * @param value the value to set.
   */
  public void setPipelineName(java.lang.String value) {
    this.pipelineName = value;
  }

  /**
   * Gets the value of the 'platformInstanceId' field.
   * The id of the instance against which the ingestion pipeline ran.
e.g.: Bigquery project ids, MySQL hostnames etc.   */
  public java.lang.String getPlatformInstanceId() {
    return platformInstanceId;
  }

  /**
   * Sets the value of the 'platformInstanceId' field.
   * The id of the instance against which the ingestion pipeline ran.
e.g.: Bigquery project ids, MySQL hostnames etc.   * @param value the value to set.
   */
  public void setPlatformInstanceId(java.lang.String value) {
    this.platformInstanceId = value;
  }

  /**
   * Gets the value of the 'config' field.
   * Json-encoded string representation of the non-secret members of the config .   */
  public java.lang.String getConfig() {
    return config;
  }

  /**
   * Sets the value of the 'config' field.
   * Json-encoded string representation of the non-secret members of the config .   * @param value the value to set.
   */
  public void setConfig(java.lang.String value) {
    this.config = value;
  }

  /**
   * Gets the value of the 'state' field.
   * Opaque blob of the state representation.   */
  public com.linkedin.pegasus2avro.datajob.datahub.IngestionCheckpointState getState() {
    return state;
  }

  /**
   * Sets the value of the 'state' field.
   * Opaque blob of the state representation.   * @param value the value to set.
   */
  public void setState(com.linkedin.pegasus2avro.datajob.datahub.IngestionCheckpointState value) {
    this.state = value;
  }

  /**
   * Gets the value of the 'runId' field.
   * The run identifier of this job.   */
  public java.lang.String getRunId() {
    return runId;
  }

  /**
   * Sets the value of the 'runId' field.
   * The run identifier of this job.   * @param value the value to set.
   */
  public void setRunId(java.lang.String value) {
    this.runId = value;
  }

  /** Creates a new DatahubIngestionCheckpoint RecordBuilder */
  public static com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder newBuilder() {
    return new com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder();
  }
  
  /** Creates a new DatahubIngestionCheckpoint RecordBuilder by copying an existing Builder */
  public static com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder newBuilder(com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder other) {
    return new com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder(other);
  }
  
  /** Creates a new DatahubIngestionCheckpoint RecordBuilder by copying an existing DatahubIngestionCheckpoint instance */
  public static com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder newBuilder(com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint other) {
    return new com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder(other);
  }
  
  /**
   * RecordBuilder for DatahubIngestionCheckpoint instances.
   */
  public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<DatahubIngestionCheckpoint>
    implements org.apache.avro.data.RecordBuilder<DatahubIngestionCheckpoint> {

    private long timestampMillis;
    private com.linkedin.pegasus2avro.timeseries.TimeWindowSize eventGranularity;
    private com.linkedin.pegasus2avro.timeseries.PartitionSpec partitionSpec;
    private java.lang.String messageId;
    private java.lang.String pipelineName;
    private java.lang.String platformInstanceId;
    private java.lang.String config;
    private com.linkedin.pegasus2avro.datajob.datahub.IngestionCheckpointState state;
    private java.lang.String runId;

    /** Creates a new Builder */
    private Builder() {
      super(com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.SCHEMA$);
    }
    
    /** Creates a Builder by copying an existing Builder */
    private Builder(com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder other) {
      super(other);
      if (isValidValue(fields()[0], other.timestampMillis)) {
        this.timestampMillis = data().deepCopy(fields()[0].schema(), other.timestampMillis);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.eventGranularity)) {
        this.eventGranularity = data().deepCopy(fields()[1].schema(), other.eventGranularity);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.partitionSpec)) {
        this.partitionSpec = data().deepCopy(fields()[2].schema(), other.partitionSpec);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.messageId)) {
        this.messageId = data().deepCopy(fields()[3].schema(), other.messageId);
        fieldSetFlags()[3] = true;
      }
      if (isValidValue(fields()[4], other.pipelineName)) {
        this.pipelineName = data().deepCopy(fields()[4].schema(), other.pipelineName);
        fieldSetFlags()[4] = true;
      }
      if (isValidValue(fields()[5], other.platformInstanceId)) {
        this.platformInstanceId = data().deepCopy(fields()[5].schema(), other.platformInstanceId);
        fieldSetFlags()[5] = true;
      }
      if (isValidValue(fields()[6], other.config)) {
        this.config = data().deepCopy(fields()[6].schema(), other.config);
        fieldSetFlags()[6] = true;
      }
      if (isValidValue(fields()[7], other.state)) {
        this.state = data().deepCopy(fields()[7].schema(), other.state);
        fieldSetFlags()[7] = true;
      }
      if (isValidValue(fields()[8], other.runId)) {
        this.runId = data().deepCopy(fields()[8].schema(), other.runId);
        fieldSetFlags()[8] = true;
      }
    }
    
    /** Creates a Builder by copying an existing DatahubIngestionCheckpoint instance */
    private Builder(com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint other) {
            super(com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.SCHEMA$);
      if (isValidValue(fields()[0], other.timestampMillis)) {
        this.timestampMillis = data().deepCopy(fields()[0].schema(), other.timestampMillis);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.eventGranularity)) {
        this.eventGranularity = data().deepCopy(fields()[1].schema(), other.eventGranularity);
        fieldSetFlags()[1] = true;
      }
      if (isValidValue(fields()[2], other.partitionSpec)) {
        this.partitionSpec = data().deepCopy(fields()[2].schema(), other.partitionSpec);
        fieldSetFlags()[2] = true;
      }
      if (isValidValue(fields()[3], other.messageId)) {
        this.messageId = data().deepCopy(fields()[3].schema(), other.messageId);
        fieldSetFlags()[3] = true;
      }
      if (isValidValue(fields()[4], other.pipelineName)) {
        this.pipelineName = data().deepCopy(fields()[4].schema(), other.pipelineName);
        fieldSetFlags()[4] = true;
      }
      if (isValidValue(fields()[5], other.platformInstanceId)) {
        this.platformInstanceId = data().deepCopy(fields()[5].schema(), other.platformInstanceId);
        fieldSetFlags()[5] = true;
      }
      if (isValidValue(fields()[6], other.config)) {
        this.config = data().deepCopy(fields()[6].schema(), other.config);
        fieldSetFlags()[6] = true;
      }
      if (isValidValue(fields()[7], other.state)) {
        this.state = data().deepCopy(fields()[7].schema(), other.state);
        fieldSetFlags()[7] = true;
      }
      if (isValidValue(fields()[8], other.runId)) {
        this.runId = data().deepCopy(fields()[8].schema(), other.runId);
        fieldSetFlags()[8] = true;
      }
    }

    /** Gets the value of the 'timestampMillis' field */
    public java.lang.Long getTimestampMillis() {
      return timestampMillis;
    }
    
    /** Sets the value of the 'timestampMillis' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder setTimestampMillis(long value) {
      validate(fields()[0], value);
      this.timestampMillis = value;
      fieldSetFlags()[0] = true;
      return this; 
    }
    
    /** Checks whether the 'timestampMillis' field has been set */
    public boolean hasTimestampMillis() {
      return fieldSetFlags()[0];
    }
    
    /** Clears the value of the 'timestampMillis' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder clearTimestampMillis() {
      fieldSetFlags()[0] = false;
      return this;
    }

    /** Gets the value of the 'eventGranularity' field */
    public com.linkedin.pegasus2avro.timeseries.TimeWindowSize getEventGranularity() {
      return eventGranularity;
    }
    
    /** Sets the value of the 'eventGranularity' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder setEventGranularity(com.linkedin.pegasus2avro.timeseries.TimeWindowSize value) {
      validate(fields()[1], value);
      this.eventGranularity = value;
      fieldSetFlags()[1] = true;
      return this; 
    }
    
    /** Checks whether the 'eventGranularity' field has been set */
    public boolean hasEventGranularity() {
      return fieldSetFlags()[1];
    }
    
    /** Clears the value of the 'eventGranularity' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder clearEventGranularity() {
      eventGranularity = null;
      fieldSetFlags()[1] = false;
      return this;
    }

    /** Gets the value of the 'partitionSpec' field */
    public com.linkedin.pegasus2avro.timeseries.PartitionSpec getPartitionSpec() {
      return partitionSpec;
    }
    
    /** Sets the value of the 'partitionSpec' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder setPartitionSpec(com.linkedin.pegasus2avro.timeseries.PartitionSpec value) {
      validate(fields()[2], value);
      this.partitionSpec = value;
      fieldSetFlags()[2] = true;
      return this; 
    }
    
    /** Checks whether the 'partitionSpec' field has been set */
    public boolean hasPartitionSpec() {
      return fieldSetFlags()[2];
    }
    
    /** Clears the value of the 'partitionSpec' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder clearPartitionSpec() {
      partitionSpec = null;
      fieldSetFlags()[2] = false;
      return this;
    }

    /** Gets the value of the 'messageId' field */
    public java.lang.String getMessageId() {
      return messageId;
    }
    
    /** Sets the value of the 'messageId' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder setMessageId(java.lang.String value) {
      validate(fields()[3], value);
      this.messageId = value;
      fieldSetFlags()[3] = true;
      return this; 
    }
    
    /** Checks whether the 'messageId' field has been set */
    public boolean hasMessageId() {
      return fieldSetFlags()[3];
    }
    
    /** Clears the value of the 'messageId' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder clearMessageId() {
      messageId = null;
      fieldSetFlags()[3] = false;
      return this;
    }

    /** Gets the value of the 'pipelineName' field */
    public java.lang.String getPipelineName() {
      return pipelineName;
    }
    
    /** Sets the value of the 'pipelineName' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder setPipelineName(java.lang.String value) {
      validate(fields()[4], value);
      this.pipelineName = value;
      fieldSetFlags()[4] = true;
      return this; 
    }
    
    /** Checks whether the 'pipelineName' field has been set */
    public boolean hasPipelineName() {
      return fieldSetFlags()[4];
    }
    
    /** Clears the value of the 'pipelineName' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder clearPipelineName() {
      pipelineName = null;
      fieldSetFlags()[4] = false;
      return this;
    }

    /** Gets the value of the 'platformInstanceId' field */
    public java.lang.String getPlatformInstanceId() {
      return platformInstanceId;
    }
    
    /** Sets the value of the 'platformInstanceId' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder setPlatformInstanceId(java.lang.String value) {
      validate(fields()[5], value);
      this.platformInstanceId = value;
      fieldSetFlags()[5] = true;
      return this; 
    }
    
    /** Checks whether the 'platformInstanceId' field has been set */
    public boolean hasPlatformInstanceId() {
      return fieldSetFlags()[5];
    }
    
    /** Clears the value of the 'platformInstanceId' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder clearPlatformInstanceId() {
      platformInstanceId = null;
      fieldSetFlags()[5] = false;
      return this;
    }

    /** Gets the value of the 'config' field */
    public java.lang.String getConfig() {
      return config;
    }
    
    /** Sets the value of the 'config' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder setConfig(java.lang.String value) {
      validate(fields()[6], value);
      this.config = value;
      fieldSetFlags()[6] = true;
      return this; 
    }
    
    /** Checks whether the 'config' field has been set */
    public boolean hasConfig() {
      return fieldSetFlags()[6];
    }
    
    /** Clears the value of the 'config' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder clearConfig() {
      config = null;
      fieldSetFlags()[6] = false;
      return this;
    }

    /** Gets the value of the 'state' field */
    public com.linkedin.pegasus2avro.datajob.datahub.IngestionCheckpointState getState() {
      return state;
    }
    
    /** Sets the value of the 'state' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder setState(com.linkedin.pegasus2avro.datajob.datahub.IngestionCheckpointState value) {
      validate(fields()[7], value);
      this.state = value;
      fieldSetFlags()[7] = true;
      return this; 
    }
    
    /** Checks whether the 'state' field has been set */
    public boolean hasState() {
      return fieldSetFlags()[7];
    }
    
    /** Clears the value of the 'state' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder clearState() {
      state = null;
      fieldSetFlags()[7] = false;
      return this;
    }

    /** Gets the value of the 'runId' field */
    public java.lang.String getRunId() {
      return runId;
    }
    
    /** Sets the value of the 'runId' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder setRunId(java.lang.String value) {
      validate(fields()[8], value);
      this.runId = value;
      fieldSetFlags()[8] = true;
      return this; 
    }
    
    /** Checks whether the 'runId' field has been set */
    public boolean hasRunId() {
      return fieldSetFlags()[8];
    }
    
    /** Clears the value of the 'runId' field */
    public com.linkedin.pegasus2avro.datajob.datahub.DatahubIngestionCheckpoint.Builder clearRunId() {
      runId = null;
      fieldSetFlags()[8] = false;
      return this;
    }

    @Override
    public DatahubIngestionCheckpoint build() {
      try {
        DatahubIngestionCheckpoint record = new DatahubIngestionCheckpoint();
        record.timestampMillis = fieldSetFlags()[0] ? this.timestampMillis : (java.lang.Long) defaultValue(fields()[0]);
        record.eventGranularity = fieldSetFlags()[1] ? this.eventGranularity : (com.linkedin.pegasus2avro.timeseries.TimeWindowSize) defaultValue(fields()[1]);
        record.partitionSpec = fieldSetFlags()[2] ? this.partitionSpec : (com.linkedin.pegasus2avro.timeseries.PartitionSpec) defaultValue(fields()[2]);
        record.messageId = fieldSetFlags()[3] ? this.messageId : (java.lang.String) defaultValue(fields()[3]);
        record.pipelineName = fieldSetFlags()[4] ? this.pipelineName : (java.lang.String) defaultValue(fields()[4]);
        record.platformInstanceId = fieldSetFlags()[5] ? this.platformInstanceId : (java.lang.String) defaultValue(fields()[5]);
        record.config = fieldSetFlags()[6] ? this.config : (java.lang.String) defaultValue(fields()[6]);
        record.state = fieldSetFlags()[7] ? this.state : (com.linkedin.pegasus2avro.datajob.datahub.IngestionCheckpointState) defaultValue(fields()[7]);
        record.runId = fieldSetFlags()[8] ? this.runId : (java.lang.String) defaultValue(fields()[8]);
        return record;
      } catch (Exception e) {
        throw new org.apache.avro.AvroRuntimeException(e);
      }
    }
  }
}
