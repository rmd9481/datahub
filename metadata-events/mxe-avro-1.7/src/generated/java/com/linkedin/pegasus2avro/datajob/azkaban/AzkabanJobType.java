/**
 * Autogenerated by Avro
 * 
 * DO NOT EDIT DIRECTLY
 */
package com.linkedin.pegasus2avro.datajob.azkaban;  
@SuppressWarnings("all")
/** The various types of support azkaban jobs */
@org.apache.avro.specific.AvroGenerated
public enum AzkabanJobType { 
  COMMAND, HADOOP_JAVA, HADOOP_SHELL, HIVE, PIG, SQL, GLUE  ;
  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse("{\"type\":\"enum\",\"name\":\"AzkabanJobType\",\"namespace\":\"com.linkedin.pegasus2avro.datajob.azkaban\",\"doc\":\"The various types of support azkaban jobs\",\"symbols\":[\"COMMAND\",\"HADOOP_JAVA\",\"HADOOP_SHELL\",\"HIVE\",\"PIG\",\"SQL\",\"GLUE\"],\"symbolDocs\":{\"COMMAND\":\"The command job type is one of the basic built-in types. It runs multiple UNIX commands using java processbuilder.\\nUpon execution, Azkaban spawns off a process to run the command.\",\"GLUE\":\"Glue type is for running AWS Glue job transforms.\",\"HADOOP_JAVA\":\"Runs a java program with ability to access Hadoop cluster.\\nhttps://azkaban.readthedocs.io/en/latest/jobTypes.html#java-job-type\",\"HADOOP_SHELL\":\"In large part, this is the same Command type. The difference is its ability to talk to a Hadoop cluster\\nsecurely, via Hadoop tokens.\",\"HIVE\":\"Hive type is for running Hive jobs.\",\"PIG\":\"Pig type is for running Pig jobs.\",\"SQL\":\"SQL is for running Presto, mysql queries etc\"}}");
  public static org.apache.avro.Schema getClassSchema() { return SCHEMA$; }
}
